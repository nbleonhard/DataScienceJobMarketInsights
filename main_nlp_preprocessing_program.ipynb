{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Preprocessing Program\n",
    "This program removes duplicate job listings and uses tokenization to search for 221 different words and/or sequences in every job listing. These results are packaged into a dataframe along with other important features and exported as a csv file for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!pip install -U word2number\n",
    "!python -m spacy download en_core_web_sm # small english model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from word2number import w2n\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import getpass\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy import create_engine\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default maximum number of columns for a data frame is 20. The below code increases this maximum number.\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "print(pd.options.display.max_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_database(sql_query, user):\n",
    "    '''\n",
    "    This function take say SQL query and queries the postgresql database.\n",
    "    It returns a dataframe containing the result of that query.\n",
    "    \n",
    "    Args:\n",
    "        sql_query: Str\n",
    "            Contains the SQL query you want to query the database with.\n",
    "        user: Str\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame\n",
    "            Contains result of your query.\n",
    "    '''\n",
    "    \n",
    "    sql_query = sql_query\n",
    "    database = \"my_database\"\n",
    "    user     = user\n",
    "    password = getpass.getpass(\"Enter password: \")\n",
    "\n",
    "    connection = psycopg2.connect(\n",
    "        database = database,\n",
    "        user = user,\n",
    "        host = 'my_host',\n",
    "        password = password)\n",
    "    \n",
    "    df = pd.read_sql_query(sql_query, connection)\n",
    "    connection.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_list():  \n",
    "    '''\n",
    "    This function returns a fresh instance of the Main Dictionary (all words/items have \n",
    "    \"found\" set to False).\n",
    "    The Main Dictionary contains all the words we want to find in the job listing description.\n",
    "    Many words have variations and these variations need to be accounted for. Some words/items\n",
    "    contain multiple tokens such as \"scikit-learn\". We need to seperate one, two, and three\n",
    "    token variations because they each require different search methods. The goal of this\n",
    "    data structure is to contain all the components necessary to do the search, contain \n",
    "    the result of the search, and be in an efficient format for time complexity. \n",
    "    '''\n",
    "    \n",
    "    main_dictionary = {\n",
    "        \"programming_query_languages\": {\n",
    "            \"python\": {\n",
    "                'one_token': [\"python\"], \n",
    "                'found': False\n",
    "            }, \n",
    "            \"r\": {\n",
    "                'one_token': [\"r\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"c++\": {\n",
    "                'one_token': [\"c++\", \"cpp\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"rust\": {\n",
    "                'one_token': [\"rust\", \"rustlang\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"sql\": {\n",
    "                'one_token': [\"sql\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"java\": {\n",
    "                'one_token': [\"java\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"javascript\": {\n",
    "                'one_token': [\"javascript\", \"js\", \"ecmascript\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"c#\": {\n",
    "                'two_token': [[\"c\", \"#\"]],\n",
    "                'found': False\n",
    "            }, \n",
    "            \"spark\": {\n",
    "                'one_token': [\"spark\"], # could be a false positive\n",
    "                'found': False\n",
    "            },  \n",
    "            \"scala\": {\n",
    "                'one_token': [\"scala\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"xml\": {\n",
    "                'one_token': [\"xml\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"vba\": {\n",
    "                'one_token': [\"vba\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"julia\": {\n",
    "                'one_token': [\"julia\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"typescript\": {\n",
    "                'one_token': [\"typescript\", \"ts\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"swift\": {\n",
    "                'one_token': [\"typescript\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"php\": {\n",
    "                'one_token': [\"php\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"ruby\": {\n",
    "                'one_token': [\"ruby\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"perl\": {\n",
    "                'one_token': [\"perl\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"matlab\": {\n",
    "                'one_token': [\"matlab\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"graphql\": {\n",
    "                'one_token': [\"graphql\"], \n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"libraries_and_packages\": {\n",
    "            \"numpy\": {\n",
    "                'one_token': [\"numpy\", \"np\"], # not sure if np is necessary\n",
    "                'found': False\n",
    "            },\n",
    "            \"pandas\": {\n",
    "                'one_token': [\"pandas\", \"pd\"], # not sure if pd is necessary\n",
    "                'found': False\n",
    "            },\n",
    "            \"spacy\": {\n",
    "                'one_token': [\"spacy\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"scikit-learn\": {\n",
    "                'one_token': [\"sklearn\", \"scikitlearn\"],\n",
    "                'two_token': [[\"scikit\", \"learn\"]],\n",
    "                'three_token': [[\"scikit\", \"-\", \"learn\"]],\n",
    "                'found': False\n",
    "            }, \n",
    "            \"pytorch\": {\n",
    "                'one_token': [\"pytorch\", \"torch\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"tensorflow\": {\n",
    "                'one_token': [\"tensorflow\", \"tf\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"dask\": {\n",
    "                'one_token': [\"dask\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"pyspark\": {\n",
    "                'one_token': [\"pyspark\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"scipy\": {\n",
    "                'one_token': [\"scipy\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"keras\": {\n",
    "                'one_token': [\"keras\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"matplotlib\": {\n",
    "                'one_token': [\"matplotlib\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"seaborn\": {\n",
    "                'one_token': [\"seaborn\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"bokeh\": {\n",
    "                'one_token': [\"bokeh\"], \n",
    "                'found': False\n",
    "            },\n",
    "            \"plotly\": {\n",
    "                'one_token': [\"plotly\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"ggplot\": {\n",
    "                'one_token': [\"ggplot\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"cloud_technologies\": {\n",
    "            \"aws\": {\n",
    "                'one_token': [\"aws\"], \n",
    "                'three_token': [[\"amazon\", \"web\", \"service\"], [\"amazon\", \"web\", \"services\"]],\n",
    "                'found': False\n",
    "            },\n",
    "            \"gcp\": {\n",
    "                'one_token': [\"gcp\"], \n",
    "                'three_token': [[\"google\", \"cloud\", \"platform\"]],\n",
    "                'found': False\n",
    "            },\n",
    "            \"azure\": {\n",
    "                'one_token': [\"azure\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"ibm_cloud\": {\n",
    "                'two_token': [[\"ibm\", \"cloud\"], [\"ibm\", \"bluemix\"]],\n",
    "                'found': False\n",
    "            },\n",
    "            \"heroku\": {\n",
    "                'one_token': [\"heroku\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"salesforce\": {\n",
    "                'one_token': [\"salesforce\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"data_visualization_tools\": {\n",
    "            \"tableau\": {\n",
    "                'one_token': [\"tableau\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"power_bi\": {\n",
    "                'two_token': [[\"power\", \"bi\"]],\n",
    "                'found': False\n",
    "            },\n",
    "            \"qlikview\": {\n",
    "                'one_token': [\"qlikview\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"d3.js\": {\n",
    "                'one_token': [\"d3.js\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"grafana\": {\n",
    "                'one_token': [\"grafana\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"looker\": {\n",
    "                'one_token': [\"looker\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"metabase\": {\n",
    "                'one_token': [\"metabase\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"database_solutions\": {\n",
    "            \"nosql\": {\n",
    "                'one_token': [\"nosql\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"mysql\": {\n",
    "                'one_token': [\"mysql\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"sql_server\": {\n",
    "                'two_token': [[\"sql\", \"server\"]],\n",
    "                'found': False\n",
    "            },\n",
    "            \"oracle\": {\n",
    "                'one_token': [\"oracle\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"postgresql\": {\n",
    "                'one_token': [\"postgresql\", \"postgres\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"mongodb\": {\n",
    "                'one_token': [\"mongodb\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"cassandra\": {\n",
    "                'one_token': [\"cassandra\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"elasticsearch\": {\n",
    "                'one_token': [\"elasticsearch\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"redis\": {\n",
    "                'one_token': [\"redis\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"neo4j\": {\n",
    "                'one_token': [\"neo4j\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"containers\": {\n",
    "            \"docker\": {\n",
    "                'one_token': [\"docker\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"kubernetes\": {\n",
    "                'one_token': [\"kubernetes\", \"k8s\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"openshift\": {\n",
    "                'one_token': [\"openshift\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"distributed_solutions\": {\n",
    "            \"hadoop\": {\n",
    "                'one_token': [\"hadoop\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"hive\": {\n",
    "                'one_token': [\"hive\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"mapreduce\": {\n",
    "                'one_token': [\"mapreduce\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"flink\": {\n",
    "                'one_token': [\"flink\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"kafka\": {\n",
    "                'one_token': [\"kafka\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"apache_beam\": {\n",
    "                'two_token': [[\"apache\", \"beam\"]],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"mlops\": {\n",
    "            \"vertexai\": {\n",
    "                'one_token': [\"vertexai\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"sagemaker\": {\n",
    "                'one_token': [\"sagemaker\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"version_control\": {\n",
    "            \"git\": {\n",
    "                'one_token': [\"git\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"cvs\": {\n",
    "                'one_token': [\"cvs\"],\n",
    "                'three_token': [[\"concurrent\", \"versions\", \"system\"]],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"os\": {\n",
    "            \"windows\": {\n",
    "                'one_token': [\"windows\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"linux\": {\n",
    "                'one_token': [\"linux\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"macos\": {\n",
    "                'one_token': [\"macos\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"project_management_frameworks\": {\n",
    "            \"agile\": {\n",
    "                'one_token': [\"agile\"],\n",
    "                'found': False\n",
    "            },\n",
    "            \"scrum\": {\n",
    "                'one_token': [\"scrum\"],\n",
    "                'found': False\n",
    "            },\n",
    "        },\n",
    "        \"subjects\": {\n",
    "            \"technical_field\": {\n",
    "                \"two_token\": [[\"technical\", \"field\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"quantitative_field\": {\n",
    "                \"two_token\": [[\"quantitative\", \"field\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"data_science\": {\n",
    "                \"two_token\": [[\"data\", \"science\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"analytics\": {\n",
    "                \"one_token\": [\"analytics\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"machine_learning\": {\n",
    "                \"one_token\": [\"ml\"],\n",
    "                \"two_token\": [[\"machine\", \"learning\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"artificial_intelligence\": {\n",
    "                \"one_token\": [\"ai\"],\n",
    "                \"two_token\": [[\"artificial\", \"intelligence\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"statistics\": {\n",
    "                \"one_token\": [\"statistics\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"mathematics\": {\n",
    "                \"one_token\": [\"mathematics\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"computer_science\": {\n",
    "                \"one_token\": [\"cs\"],\n",
    "                \"two_token\": [[\"computer\", \"science\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"engineering\": {\n",
    "                \"one_token\": [\"engineering\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"electrical_engineering\": {\n",
    "                \"two_token\": [[\"electrical\", \"engineering\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"computer_engineering\": {\n",
    "                \"two_token\": [[\"computer\", \"engineering\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"finance\": {\n",
    "                \"one_token\": [\"finance\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"psychology\": {\n",
    "                \"one_token\": [\"psychology\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"economics\": {\n",
    "                \"one_token\": [\"economics\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"information_technology\": {\n",
    "                \"two_token\": [[\"information\", \"technology\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"probability\": {\n",
    "                \"one_token\": [\"probability\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"operational_research\": {\n",
    "                \"two_token\": [[\"operational\", \"research\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"geography\": {\n",
    "                \"one_token\": [\"geography\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"physics\": {\n",
    "                \"one_token\": [\"physics\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"education_levels\": {\n",
    "            \"phd\": {\n",
    "                \"one_token\": [\"doctorate\", \"phd\", \"ph.d.\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"masters\": {\n",
    "                \"one_token\": [\"master\", \"masters\", \"ms\", \"m.s.\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"bachelors\": {\n",
    "                \"one_token\": [\"bachelor\", \"bachelors\", \"bs\", \"ba\", \"b.s.\", \"b.a.\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"reporting_packages\": {\n",
    "            \"crystal_reports\": {\n",
    "                \"two_token\": [[\"crystal\", \"reports\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"ssrs\": {\n",
    "                \"one_token\": [\"ssrs\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"excel\": {\n",
    "                \"one_token\": [\"excel\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"job_titles\": {\n",
    "            \"data_scientist\": {\n",
    "                \"two_token\": [[\"data\", \"scientist\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"data_analyst\": {\n",
    "                \"two_token\": [[\"data\", \"analyst\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"machine_learning_engineer\": {\n",
    "                \"three_token\": [[\"machine\", \"learning\", \"engineer\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"computer_programmer\": {\n",
    "                \"two_token\": [[\"computer\", \"programmer\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"software_engineer\": {\n",
    "                \"two_token\": [[\"software\", \"engineer\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"statistician\": {\n",
    "                \"one_token\": [\"statistician\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"mathematician\": {\n",
    "                \"one_token\": [\"mathematician\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"business_intelligence_analyst\": {\n",
    "                \"three_token\": [[\"business\", \"intelligence\", \"analyst\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"engineer\": {\n",
    "                \"one_token\": [\"engineer\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"database_administrator\": {\n",
    "                \"two_token\": [[\"database\", \"administrator\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"statistics\": {\n",
    "            \"hypothesis_testing\": {\n",
    "                \"two_token\": [[\"hypothesis\", \"testing\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"variance\": {\n",
    "                \"one_token\": [\"variance\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"correlation\": {\n",
    "                \"one_token\": [\"correlation\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"standard_deviation\": {\n",
    "                \"two_token\": [[\"standard\", \"deviation\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"univariate\": {\n",
    "                \"one_token\": [\"univariate\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"multivariate\": {\n",
    "                \"one_token\": [\"multivariate\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"qualitative_variables\": {\n",
    "                \"two_token\": [[\"qualitative\", \"variables\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"quantitative_variables\": {\n",
    "                \"two_token\": [[\"quantitative\", \"variables\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"descriptive_statistics\": {\n",
    "                \"two_token\": [[\"descriptive\", \"statistics\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"inferential_statistics\": {\n",
    "                \"two_token\": [[\"inferential\", \"statistics\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"test_statistic\": {\n",
    "                \"two_token\": [[\"test\", \"statistic\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"chi_squared\": {\n",
    "                \"two_token\": [[\"chi\", \"square\"], [\"chi\", \"squared\"]],\n",
    "                \"three_token\": [[\"chi\", \"-\", \"square\"], [\"chi\", \"-\", \"squared\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"p_value\": {\n",
    "                \"two_token\": [[\"p\", \"value\"], [\"p\", \"values\"]],\n",
    "                \"three_token\": [[\"p\", \"-\", \"value\"], [\"p\", \"-\", \"values\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"t_test\": {\n",
    "                \"two_token\": [[\"t\", \"test\"], [\"t\", \"tests\"]],\n",
    "                \"three_token\": [[\"t\", \"-\", \"test\"], [\"t\", \"-\", \"tests\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"z_test\": {\n",
    "                \"two_token\": [[\"z\", \"test\"], [\"z\", \"tests\"]],\n",
    "                \"three_token\": [[\"z\", \"-\", \"test\"], [\"z\", \"-\", \"tests\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"normal_distributions\": {\n",
    "                \"two_token\": [[\"normal\", \"distribution\"], [\"normal\", \"distributions\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"central_limit_theorem\": {\n",
    "                \"one_token\": [\"clt\"],\n",
    "                \"three_token\": [[\"central\", \"limit\", \"theorem\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"poisson_distributions\": {\n",
    "                \"two_token\": [[\"poisson\", \"distribution\"], [\"poisson\", \"distributions\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"confidence_intervals\": {\n",
    "                \"two_token\": [[\"confidence\", \"interval\"], [\"confidence\", \"intervals\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"type_i_errors\": {\n",
    "                \"three_token\": [[\"type\", \"i\", \"error\"], [\"type\", \"i\", \"errors\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"type_ii_errors\": {\n",
    "                \"three_token\": [[\"type\", \"ii\", \"error\"], [\"type\", \"ii\", \"errors\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"maximum_likelihood_estimation\": {\n",
    "                \"three_token\": [[\"maximum\", \"likelihood\", \"estimation\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"a_b_testing\": {\n",
    "                'three_token': [[\"a\", \"/\", \"b\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"conditional_probability\": {\n",
    "                \"two_token\": [[\"conditional\", \"probability\"], [\"conditional\", \"probabilities\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"bayes_rule\": {\n",
    "                \"two_token\": [[\"bayes\", \"rule\"], [\"bayes'\", \"rule\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"random_variables\": {\n",
    "                \"two_token\": [[\"random\", \"variable\"], [\"random\", \"variables\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"discrete_variable\": {\n",
    "                \"two_token\": [[\"discrete\", \"variable\"], [\"discrete\", \"variables\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"continuous_variable\": {\n",
    "                \"two_token\": [[\"continuous\", \"variable\"], [\"continuous\", \"variables\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"probability_distributions\": {\n",
    "                \"two_token\": [[\"probability\", \"distribution\"], [\"probability\", \"distributions\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"markov_chains\": {\n",
    "                \"two_token\": [[\"markov\", \"chains\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"confusion_matrix\": {\n",
    "                \"two_token\": [[\"confusion\", \"matrix\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \n",
    "        },\n",
    "        \"computer_science\": {\n",
    "            \"time_complexity\": {\n",
    "                \"two_token\": [[\"time\", \"complexity\"]],\n",
    "                \"three_token\": [[\"big\", \"-\", \"o\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"data_structures\": {\n",
    "                \"two_token\": [[\"data\", \"structures\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"recursion\": {\n",
    "                \"one_token\": [\"recursion\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"algorithms\": {\n",
    "                \"one_token\": [\"algorithms\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"stacks\": {\n",
    "                \"one_token\": [\"stacks\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"queues\": {\n",
    "                \"one_token\": [\"queues\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"heaps\": {\n",
    "                \"one_token\": [\"heaps\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"linked_lists\": {\n",
    "                \"two_token\": [[\"linked\", \"lists\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"hash_maps\": {\n",
    "                \"two_token\": [[\"hash\", \"maps\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"binary_search_trees\": {\n",
    "                \"three_token\": [[\"binary\", \"search\", \"trees\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"skills\": {\n",
    "            \"scripting\": {\n",
    "                \"one_token\": [\"scripting\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"designing\": {\n",
    "                \"one_token\": [\"designing\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"software_development\": {\n",
    "                \"two_token\": [[\"software\", \"development\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"software_engineering\": {\n",
    "                \"two_token\": [[\"software\", \"engineering\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"programming\": {\n",
    "                \"one_token\": [\"programming\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"querying\": {\n",
    "                \"one_token\": [\"querying\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"full_stack\": {\n",
    "                \"two_token\": [[\"full\", \"stack\"]],\n",
    "                \"three_token\": [[\"full\", \"-\", \"stack\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"automation\": {\n",
    "                \"one_token\": [\"automation\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"communication\": {\n",
    "                \"one_token\": [\"communication\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"optimization\": {\n",
    "                \"one_token\": [\"optimization\", \"optimizing\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"etl\": {\n",
    "                \"one_token\": [\"etl\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"problem_solving\": {\n",
    "                \"two_token\": [[\"problem\", \"solving\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"forecasting\": {\n",
    "                \"one_token\": [\"forecasting\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"machine_learning\": {\n",
    "            \"data_mining\": {\n",
    "                \"two_token\": [[\"data\", \"mining\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"nlp\": {\n",
    "                \"one_token\": [\"nlp\"],\n",
    "                'three_token': [[\"natural\", \"language\", \"processing\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"regression\": {\n",
    "                \"one_token\": [\"regression\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"classification\": {\n",
    "                \"one_token\": [\"classification\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"naive_bayes\": {\n",
    "                \"two_token\": [[\"naive\", \"bayes\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"clustering\": {\n",
    "                \"one_token\": [\"clustering\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"decision_tree\": {\n",
    "                \"two_token\": [[\"decision\", \"tree\"], [\"decision\", \"trees\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"random_forest\": {\n",
    "                \"two_token\": [[\"random\", \"forest\"], [\"random\", \"forests\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"gradient_boosting\": {\n",
    "                \"two_token\": [[\"gradient\", \"boost\"], [\"gradient\", \"boosting\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"ensemble\": {\n",
    "                \"one_token\": [\"ensemble\", \"ensembles\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"boosting\": {\n",
    "                \"one_token\": [\"boosting\", \"ensembles\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"mixture_of_experts\": {\n",
    "                \"one_token\": [\"moe\"],\n",
    "                \"three_token\": [[\"mixture\", \"of\", \"experts\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"neural_network\": {\n",
    "                \"two_token\": [[\"neural\", \"network\"], [\"neural\", \"networks\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"anomaly_detection\": {\n",
    "                \"two_token\": [[\"anomaly\", \"detection\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"preprocessing\": {\n",
    "                \"one_token\": [\"preprocessing\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"normalization\": {\n",
    "                \"one_token\": [\"normalization\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"standardization\": {\n",
    "                \"one_token\": [\"standardization\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"support_vector_machines\": {\n",
    "                \"one_token\": [\"svm\"],\n",
    "                \"three_token\": [[\"support\", \"vector\", \"machine\"], [\"support\", \"vector\", \"machines\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"recommender_systems\": {\n",
    "                \"two_token\": [[\"recommender\", \"system\"], [\"recommender\", \"systems\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"computer_vision\": {\n",
    "                \"two_token\": [[\"computer\", \"vision\"], [\"computer\", \"visioning\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"convolutional_neural_netorks\": {\n",
    "                \"one_token\": [\"cnn\"],\n",
    "                \"three_token\": [[\"convolutional\", \"neural\", \"network\"], [\"convolutional\", \"neural\", \"networks\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"recurrent_neural_networks\": {\n",
    "                \"one_token\": [\"rnn\"],\n",
    "                \"three_token\": [[\"recurrent\", \"neural\", \"network\"], [\"recurrent\", \"neural\", \"networks\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"graph_neural_networks\": {\n",
    "                \"one_token\": [\"gnn\"],\n",
    "                \"three_token\": [[\"graph\", \"neural\", \"network\"], [\"graph\", \"neural\", \"networks\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"transfer_learning\": {\n",
    "                \"two_token\": [[\"transfer\", \"learning\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"belief_networks\": {\n",
    "                \"two_token\": [[\"belief\", \"network\"], [\"belief\", \"networks\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"gradient_descent\": {\n",
    "                \"two_token\": [[\"gradient\", \"descent\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"overfitting\": {\n",
    "                \"one_token\": [\"overfit\", \"overfitting\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"underfitting\": {\n",
    "                \"one_token\": [\"underfit\", \"underfitting\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"regularization\": {\n",
    "                \"one_token\": [\"regularization\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"cross_validation\": {\n",
    "                \"two_token\": [[\"cross\", \"validation\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"bagging\": {\n",
    "                \"one_token\": [\"bagging\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"bootstrapping\": {\n",
    "                \"one_token\": [\"bootstrapping\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"hyperparameter_tuning\": {\n",
    "                \"two_token\": [[\"hyperparameter\", \"tuning\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"principal_component_analysis\": {\n",
    "                \"one_token\": [\"pca\"],\n",
    "                \"three_token\": [[\"principle\", \"component\", \"analysis\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"dimensionality_reduction\": {\n",
    "                \"two_token\": [[\"dimensionality\", \"reduction\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"logistic_regression\": {\n",
    "                \"two_token\": [[\"logistic\", \"regression\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"sentiment_analysis\": {\n",
    "                \"two_token\": [[\"sentiment\", \"analysis\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"social_groups\": {\n",
    "            \"clients\": {\n",
    "                \"one_token\": [\"clients\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"stakeholders\": {\n",
    "                \"one_token\": [\"stakeholders\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"teammates\": {\n",
    "                \"one_token\": [\"teammates\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"partners\": {\n",
    "                \"one_token\": [\"partners\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"modeling\": {\n",
    "            \"quantitative_modeling\": {\n",
    "                \"two_token\": [[\"quantitative\", \"models\"], [\"quantitative\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"market_mix_modeling\": {\n",
    "                \"one_token\": [\"mmm\"],\n",
    "                \"three_token\": [[\"market\", \"mix\", \"models\"], [\"market\", \"mix\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"large_language_models\": {\n",
    "                \"one_token\": [\"llm\"],\n",
    "                \"three_token\": [[\"large\", \"language\", \"models\"], [\"large\", \"language\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"predictive_modeling\": {\n",
    "                \"two_token\": [[\"predictive\", \"models\"], [\"predictive\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"statistical_modeling\": {\n",
    "                \"two_token\": [[\"statistical\", \"models\"], [\"statistical\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"stochastic_modeling\": {\n",
    "                \"two_token\": [[\"stochastic\", \"models\"], [\"stochastic\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"generative_modeling\": {\n",
    "                \"two_token\": [[\"generative\", \"models\"], [\"generative\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"transformer_modeling\": {\n",
    "                \"two_token\": [[\"transformer\", \"models\"], [\"transformer\", \"modeling\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "        },\n",
    "        \"other\": {\n",
    "            \"startup\": {\n",
    "                \"one_token\": [\"startup\"],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"remote\": {\n",
    "                \"one_token\": [\"remote\"],\n",
    "                \"two_token\": [[\"fully\", \"remote\"]],\n",
    "                \"three_token\": [[\"fully\", \"-\", \"remote\"], [\"remote\", \"-\", \"based\"], [\"work\", \"from\", \"home\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"in-office\": {\n",
    "                \"three_token\": [[\"in\", \"-\", \"office\"], [\"office\", \"-\", \"based\"], [\"in\", \"-\", \"person\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"full-time\": {\n",
    "                \"two_token\": [[\"full\", \"time\"]],\n",
    "                \"three_token\": [[\"full\", \"-\", \"time\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"part-time\": {\n",
    "                \"two_token\": [[\"part\", \"time\"]],\n",
    "                \"three_token\": [[\"full\", \"-\", \"time\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "            \"hybrid\": {\n",
    "                \"one_token\": [\"hybrid\"],\n",
    "                \"two_token\": [[\"hybrid\", \"role\"]],\n",
    "                \"found\": False\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    return main_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_items(dictionary):\n",
    "    '''\n",
    "    This is a convenience function to display the total number of words/items\n",
    "    in the Main Dictionary.\n",
    "    '''\n",
    "    number_of_items = 0\n",
    "    for category in dictionary:\n",
    "        for item in dictionary[category]:\n",
    "            number_of_items += 1\n",
    "        \n",
    "    return number_of_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_contents(dictionary):\n",
    "    '''\n",
    "    This is a convenience function to display all the words/items in the Main Dictionary\n",
    "    '''\n",
    "    for category in dictionary:\n",
    "        print(category, ':')\n",
    "        for item in dictionary[category]:\n",
    "            print(\"\\t\", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tokens(dictionary, doc):\n",
    "    '''\n",
    "    The function takes every word/token in the job description and checks if that word/token \n",
    "    is in the Main Dictionary. If it is, it flags that item as found in the Main Dictionary. \n",
    "    The Main Dictionary is then returned. \n",
    "    \n",
    "    Args:\n",
    "        dictionary : Dict\n",
    "            A fresh instance of the Main Dictionary\n",
    "        doc : spacy.tokens.doc.Doc\n",
    "            The tokenized job description \n",
    "    \n",
    "    Returns:\n",
    "        Dict\n",
    "            Main Dictionary with variable \"found\" set to \"True\" for each word found during the search.\n",
    "    '''\n",
    "    \n",
    "    # Search for all one token words\n",
    "    for token in doc:\n",
    "        for category in dictionary:\n",
    "            for item in dictionary[category]:\n",
    "                if dictionary[category][item][\"found\"] == True:\n",
    "                    continue\n",
    "                else:\n",
    "                    if 'one_token' in dictionary[category][item]:\n",
    "                        if token.text.lower() in dictionary[category][item]['one_token']:\n",
    "                            dictionary[category][item]['found'] = True\n",
    "    \n",
    "    # Search for all two token words    \n",
    "    for i in range(len(doc) - 2 + 1):\n",
    "        for category in dictionary:\n",
    "            for item in dictionary[category]:\n",
    "                if dictionary[category][item][\"found\"] == True:\n",
    "                    continue\n",
    "                else:\n",
    "                    if 'two_token' in dictionary[category][item]:\n",
    "                        if [token.text.lower() for token in doc[i:i+2]] in dictionary[category][item]['two_token']:\n",
    "                            dictionary[category][item]['found'] = True\n",
    "    \n",
    "    # Search for all three token words\n",
    "    for i in range(len(doc) - 3 + 1):\n",
    "        for category in dictionary:\n",
    "            for item in dictionary[category]:\n",
    "                if dictionary[category][item][\"found\"] == True:\n",
    "                    continue\n",
    "                else:\n",
    "                    if 'three_token' in dictionary[category][item]:\n",
    "                        if [token.text.lower() for token in doc[i:i+3]] in dictionary[category][item]['three_token']:\n",
    "                            dictionary[category][item]['found'] = True\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(df):\n",
    "    '''\n",
    "    This gets the search results for every all job listings and packages them\n",
    "    into a dataframe. This dataframe is then returned to the caller. \n",
    "    \n",
    "    Args:\n",
    "        df : pandas.core.frame.DataFrame\n",
    "            The dataframe containing the job listing data scraped from Google\n",
    "    \n",
    "    Returns:\n",
    "        Dict\n",
    "            Dictionary containing the search results and other features\n",
    "    '''\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        temp_dict = {}\n",
    "\n",
    "        temp_dict[\"job_id\"] = row[\"job_id\"]\n",
    "        temp_dict[\"title\"] = row[\"title\"]\n",
    "        temp_dict[\"search_term\"] = row[\"search_term\"]\n",
    "        temp_dict[\"location\"] = row[\"location\"]\n",
    "        temp_dict[\"schedule_type\"] = row[\"schedule_type\"]\n",
    "        temp_dict[\"work_from_home\"] = row[\"work_from_home\"]\n",
    "\n",
    "        search_list = get_search_list()\n",
    "        # See which items in the main dictionary were found\n",
    "        search_list_results = find_tokens(search_list, nlp(row['description']))\n",
    "        \n",
    "        # Each column is a word, and each value is whether that word was found in that job listing\n",
    "        for category in search_list_results:\n",
    "            for item in search_list_results[category]:\n",
    "                temp_dict[item] = search_list_results[category][item][\"found\"]\n",
    "        \n",
    "        # Add this row into the temp_dict dictionary\n",
    "        results = results.append(temp_dict, ignore_index=True)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        if counter % 100 == 0:\n",
    "            print(counter, \"job descriptions searched\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Elapsed time:\", elapsed_time, \"seconds\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_title_based_on_parts(title):\n",
    "    '''\n",
    "    This function classifies titles based on combinations of individual words\n",
    "    found in the title. So no sequences of words like [\"machine\", \"learning\", \"engineering\"]. \n",
    "    This is used to label titles like \"Software Engineer-Machine Learning\".\n",
    "    \n",
    "    Args:\n",
    "        title : spacy.tokens.doc.Doc\n",
    "            The tokenized job title \n",
    "    \n",
    "    Returns:\n",
    "        Dict\n",
    "            Returns which job roles were found in the title\n",
    "    '''\n",
    "    \n",
    "    has_data = False\n",
    "    has_scientist = False\n",
    "    has_analyst = False\n",
    "    has_machine = False\n",
    "    has_learning = False\n",
    "    has_engineer = False\n",
    "    has_business = False\n",
    "    has_intelligence = False\n",
    "    has_software = False\n",
    "    \n",
    "    data = [\"data\"]\n",
    "    scientist = [\"scientist\", \"science\"]\n",
    "    analyst = [\"analyst\", \"analytics\", \"analysis\", \"analysts\"]\n",
    "    machine = [\"machine\"]\n",
    "    learning = [\"learning\"]\n",
    "    engineer = [\"engineer\", \"engineering\"]\n",
    "    business = [\"business\"]\n",
    "    intelligence = [\"intelligence\"]\n",
    "    software = [\"software\"]\n",
    "    \n",
    "    ds_label = False \n",
    "    da_label = False \n",
    "    de_label = False\n",
    "    mle_label = False\n",
    "    bia_label = False\n",
    "    \n",
    "    for token in title:\n",
    "        if token.text.lower() in data:\n",
    "            has_data = True\n",
    "        if token.text.lower() in scientist:\n",
    "            has_scientist = True\n",
    "        if token.text.lower() in analyst:\n",
    "            has_analyst = True\n",
    "        if token.text.lower() in machine:\n",
    "            has_machine = True\n",
    "        if token.text.lower() in learning:\n",
    "            has_learning = True\n",
    "        if token.text.lower() in engineer:\n",
    "            has_engineer = True\n",
    "        if token.text.lower() in business:\n",
    "            has_business = True\n",
    "        if token.text.lower() in intelligence:\n",
    "            has_intelligence = True\n",
    "        if token.text.lower() in software:\n",
    "            has_software = True\n",
    "    \n",
    "    if (has_data == True) & (has_scientist == True) & (has_business == False) & (has_intelligence == False) & (has_engineer == False):\n",
    "        ds_label = True\n",
    "    if (has_machine == True) & (has_learning == True) & (has_engineer == True):\n",
    "        mle_label = True\n",
    "    if (has_data == True) & (has_analyst == True) & (has_business == False) & (has_intelligence == False) & (has_engineer == False):\n",
    "        da_label = True\n",
    "    if (has_data == True) & (has_engineer == True) & (has_analyst == False) & (has_machine == False) * (has_software == False):\n",
    "        de_label = True\n",
    "#     if (has_analyst == True) & (has_business == True) & (has_intelligence == False) & \n",
    "#     (has_engineer == False):\n",
    "#         bia_label = True\n",
    "\n",
    "    return {\"data_scientist\": ds_label,\n",
    "            \"data_analyst\": da_label,\n",
    "            \"data_engineer\": de_label,\n",
    "            \"ml_engineer\": mle_label,\n",
    "            \"bi_analyst\": bia_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_title(title):\n",
    "    '''\n",
    "    This function accurately labels each job listing as a \n",
    "    data scientist, data analyst, data engineer, ml engineer, and/or bi analyst.\n",
    "    This is based on the job listings title.\n",
    "    A single job listing can have zero, one, or multiple title labels.\n",
    "    \n",
    "    Args:\n",
    "        title : spacy.tokens.doc.Doc\n",
    "            The tokenized job title \n",
    "    \n",
    "    Returns:\n",
    "        Dict\n",
    "            Returns which job roles were found in the title\n",
    "    '''\n",
    "    \n",
    "    title_labels = {\n",
    "        \"data_scientist\": {\n",
    "            \"two_token\": [[\"data\", \"scientist\"], [\"data\", \"science\"], [\"data\", \"scientists\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"data_analyst\": {\n",
    "            \"two_token\": [[\"data\", \"analyst\"], [\"data\", \"analysis\"], [\"data\", \"analytics\"], [\"data\", \"analysts\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"data_engineer\": {\n",
    "            \"two_token\": [[\"data\", \"engineer\"], [\"data\", \"engineering\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"ml_engineer\": { \n",
    "            \"two_token\": [[\"ml\", \"engineer\"], [\"ml\", \"engineering\"], \n",
    "    #                       [\"software\", \"engineer\"], [\"software\", \"engineering\"], \n",
    "                          [\"ai\", \"engineer\"], [\"ai\", \"engineering\"], [\"ai\", \"developer\"]],\n",
    "            \"three_token\": [[\"machine\", \"learning\", \"engineer\"], [\"machine\", \"learning\", \"engineering\"], \n",
    "                            [\"deep\", \"learning\", \"engineer\"], [\"artificial\", \"intelligence\", \"engineer\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"bi_analyst\": {\n",
    "            \"two_token\": [[\"bi\", \"analyst\"], [\"bi\", \"analysis\"], [\"bi\", \"analytics\"], [\"intelligence\", \"analyst\"], \n",
    "                          [\"intelligence\", \"analysis\"], [\"intelligence\", \"analytics\"], [\"business\", \"intelligence\"],\n",
    "                          [\"business\", \"analyst\"], [\"business\", \"analysis\"], [\"business\", \"analytics\"], [\"business\", \"analysts\"]],\n",
    "            \"three_token\": [[\"business\", \"intelligence\", \"analyst\"], [\"business\", \"intelligence\", \"analysis\"], \n",
    "                            [\"business\", \"intelligence\", \"analytics\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for token in title:\n",
    "        for label in title_labels:\n",
    "            if title_labels[label][\"found\"] == True:\n",
    "                continue\n",
    "            else:\n",
    "                if \"one_token\" in title_labels[label]:\n",
    "                    if token.text.lower() in title_labels[label][\"one_token\"]:\n",
    "                        title_labels[label][\"found\"] = True\n",
    "    for i in range(len(title) - 2 + 1):\n",
    "        for label in title_labels:\n",
    "            if title_labels[label][\"found\"] == True:\n",
    "                continue\n",
    "            else:\n",
    "                if \"two_token\" in title_labels[label]:\n",
    "                    if [token.text.lower() for token in title[i:i+2]] in title_labels[label][\"two_token\"]:\n",
    "                        title_labels[label][\"found\"] = True\n",
    "    for i in range(len(title) - 3 + 1):\n",
    "        for label in title_labels:\n",
    "            if title_labels[label][\"found\"] == True:\n",
    "                continue\n",
    "            else:\n",
    "                if \"three_token\" in title_labels[label]:\n",
    "                    if [token.text.lower() for token in title[i:i+3]] in title_labels[label][\"three_token\"]:\n",
    "                        title_labels[label][\"found\"] = True\n",
    "    \n",
    "    # If all labels are False use this function classify_title_based_on_parts()\n",
    "    if (title_labels[\"data_scientist\"][\"found\"] == False) & (title_labels[\"data_analyst\"][\"found\"] == False) & (title_labels[\"data_engineer\"][\"found\"] == False) & (title_labels[\"ml_engineer\"][\"found\"] == False) & (title_labels[\"bi_analyst\"][\"found\"] == False):\n",
    "        results = classify_title_based_on_parts(title)\n",
    "        title_labels[\"data_scientist\"][\"found\"] = results[\"data_scientist\"]\n",
    "        title_labels[\"data_analyst\"][\"found\"] = results[\"data_analyst\"]\n",
    "        title_labels[\"data_engineer\"][\"found\"] = results[\"data_engineer\"]\n",
    "        title_labels[\"ml_engineer\"][\"found\"] = results[\"ml_engineer\"]\n",
    "        title_labels[\"bi_analyst\"][\"found\"] = results[\"bi_analyst\"]\n",
    "    \n",
    "    return title_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_xor_country(location):\n",
    "    '''\n",
    "    This function takes a location and parses out the state code.\n",
    "    If there is no state code but there is a state name, the state name is mapped to \n",
    "    its state code. \n",
    "    If there is no state code and no state name, it is either a country, \"anywhere\", or null.\n",
    "    \n",
    "    Args:\n",
    "        location : Str\n",
    "            The location of the job for a particular job listing\n",
    "    \n",
    "    Returns:\n",
    "        Str\n",
    "            Returns state code  \n",
    "    '''\n",
    "    \n",
    "    pattern = r\"\\b[A-Z]{2}\\b\"\n",
    "    \n",
    "    state_mapping = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "    }\n",
    "    \n",
    "    state_list = [state_mapping[state] for state in state_mapping].append('DC')\n",
    "    \n",
    "    if type(location) != str:\n",
    "        return np.nan\n",
    "    elif re.findall(pattern, location) and len(re.findall(pattern, location)[0]) > 1:\n",
    "        return(re.findall(pattern, location)[-1])\n",
    "    elif re.findall(pattern, location) and re.findall(pattern, location)[0] in state_list:\n",
    "        return(re.findall(pattern, location)[0])\n",
    "    elif \"other\" in location:\n",
    "        if len(location.split()) > 3:\n",
    "            if location.split()[0] + \" \" + location.split()[1] in state_mapping:\n",
    "                return(state_mapping[location.split()[0] + \" \" + location.split()[1]])\n",
    "            else:\n",
    "                return(location.split()[0] + \" \" + location.split()[1])\n",
    "        elif location.split()[0] in state_mapping:\n",
    "            return(state_mapping[location.split()[0]])\n",
    "        else:\n",
    "            return(location.split()[0])\n",
    "    else:\n",
    "        if len(location.split()) > 1:\n",
    "            if location.split()[0] + \" \" + location.split()[1] in state_mapping:\n",
    "                return(state_mapping[location.split()[0] + \" \" + location.split()[1]])\n",
    "            else:\n",
    "                return(location.split()[0] + \" \" + location.split()[1])\n",
    "        elif location.split()[0] in state_mapping:\n",
    "            return(state_mapping[location.split()[0]])\n",
    "        else:\n",
    "            return(location.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_job_levels(title):\n",
    "    '''\n",
    "    This functions assigns a job level based on words and numbers in the title.\n",
    "    \n",
    "    Args:\n",
    "        title : spacy.tokens.doc.Doc\n",
    "            The tokenized job title \n",
    "    \n",
    "    Returns:\n",
    "        Dict\n",
    "            Returns which job levels were found in the title \n",
    "    '''\n",
    "    \n",
    "    job_levels = {\n",
    "        \"junior\": {\n",
    "            \"one_token\": [\"junior\", \"jr\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"senior\": {\n",
    "            \"one_token\": [\"senior\", \"sr\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"principal\": {\n",
    "            \"one_token\": [\"principal\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"lead\": {\n",
    "            \"one_token\": [\"lead\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"i\": {\n",
    "            \"one_token\": [\"i\", \"1\"], # maybe remove the number\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"ii\": {\n",
    "            \"one_token\": [\"ii\", \"2\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"iii\": {\n",
    "            \"one_token\": [\"iii\", \"3\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"vice_president\": {\n",
    "            \"one_token\": [\"vp\"],\n",
    "            \"two_token\": [[\"vice\", \"president\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"entry_level\": {\n",
    "            \"two_token\": [[\"entry\", \"level\"]],\n",
    "            \"found\": False\n",
    "        },\n",
    "        \"internship\": {\n",
    "            \"one_token\": [\"intern\", \"internship\"],\n",
    "            \"found\": False\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for token in title:\n",
    "        for level in job_levels:\n",
    "            if job_levels[level][\"found\"] == True:\n",
    "                continue\n",
    "            else:\n",
    "                if \"one_token\" in job_levels[level]:\n",
    "                    if token.text.lower() in job_levels[level][\"one_token\"]:\n",
    "                        job_levels[level][\"found\"] = True\n",
    "    for i in range(len(title) - 2 + 1):\n",
    "        for level in job_levels:\n",
    "            if job_levels[level][\"found\"] == True:\n",
    "                continue\n",
    "            else:\n",
    "                if \"two_token\" in job_levels[level]:\n",
    "                    if [token.text.lower() for token in title[i:i+2]] in job_levels[level][\"two_token\"]:\n",
    "                        job_levels[level][\"found\"] = True\n",
    "    \n",
    "    return job_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_labels(title):\n",
    "    '''\n",
    "    This function returns the title labels for a job title.\n",
    "\n",
    "    Args:\n",
    "        title : Str\n",
    "            The title string\n",
    "    \n",
    "    Returns:\n",
    "        Tuple\n",
    "            Returns tuple of boolean values corresponding to which job roles were identified in the title\n",
    "    '''\n",
    "    \n",
    "    # Replaces all characters in the string title that are not alphanumeric or whitespace with a space.\n",
    "    title = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", title)\n",
    "    \n",
    "    classified_titles = classify_title(nlp(title))\n",
    "    \n",
    "    return (\n",
    "        classified_titles[\"data_scientist\"][\"found\"],\n",
    "        classified_titles[\"data_analyst\"][\"found\"],\n",
    "        classified_titles[\"data_engineer\"][\"found\"],\n",
    "        classified_titles[\"ml_engineer\"][\"found\"],\n",
    "        classified_titles[\"bi_analyst\"][\"found\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_levels(title):\n",
    "    \n",
    "    '''\n",
    "    This function returns the job levels for a job title.\n",
    "    \n",
    "    Args:\n",
    "        title : Str\n",
    "            The title string\n",
    "    \n",
    "    Returns:\n",
    "        Tuple\n",
    "            Returns tuple of boolean values corresponding to which job levels were identified in the title    \n",
    "    '''\n",
    "    \n",
    "    job_levels = find_job_levels(nlp(title))\n",
    "    return (\n",
    "        job_levels[\"junior\"][\"found\"],\n",
    "        job_levels[\"senior\"][\"found\"],\n",
    "        job_levels[\"principal\"][\"found\"],\n",
    "        job_levels[\"lead\"][\"found\"],\n",
    "        job_levels[\"i\"][\"found\"],\n",
    "        job_levels[\"ii\"][\"found\"],\n",
    "        job_levels[\"iii\"][\"found\"],\n",
    "        job_levels[\"vice_president\"][\"found\"],\n",
    "        job_levels[\"entry_level\"][\"found\"],\n",
    "        job_levels[\"internship\"][\"found\"]      \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'my_schema'\n",
    "table = 'my_table'\n",
    "username = 'username'\n",
    "\n",
    "sql_query = 'SELECT * FROM {}.{};'.format(schema, table)\n",
    "df = query_database(sql_query, username)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove duplicate job listings with the same discription, location, and company name\n",
    "'''\n",
    "unique_rows = df[~df.duplicated(subset=['description', 'location', 'company_name'], keep=\"first\")]\n",
    "unique_rows = unique_rows.reset_index(drop=True)\n",
    "unique_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Search for 221 words pertaining to the data industry\n",
    "'''\n",
    "results = get_search_results(unique_rows)\n",
    "results = results.reset_index(drop=True)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get job labels\n",
    "'''\n",
    "results['ds_label'], results['da_label'], results['de_label'], results['mle_label'], results['bia_label'] = zip(*results['title'].apply(get_title_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get states xor countries\n",
    "'''\n",
    "results['state_xor_country'] = results['location'].apply(get_state_xor_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get job levels\n",
    "'''\n",
    "results['junior'], results['senior'], results['principal'], results['lead'], results['level_i'], results['level_ii'], results['level_iii'], results['vice_president'], results['entry_level'], results['internship'] = zip(*results['title'].apply(get_job_levels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get number of job labels\n",
    "'''\n",
    "results['num_job_labels'] = results['ds_label'].astype(int) + results['da_label'].astype(int) + results['de_label'].astype(int) + results['mle_label'].astype(int) + results['bia_label'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get number of education labels\n",
    "'''\n",
    "results['num_edu_labels'] = results['bachelors'].astype(int) + results['masters'].astype(int) + results['phd'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/my_filepath/results.csv'\n",
    "results.to_csv(file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
